{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Credit Card Fraud\n",
    "\n",
    "Your task is to use Logistic Regression and create a predictive model to determine if a transaction is fraudulent or not, based on a subset of the dataset called \"synthetic financial dataset\" available in kaggle.\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "1. Let’s begin by loading the data into a pandas DataFrame named transactions. How many transactions are fraudulent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   step      type     amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0   206  CASH_OUT   62927.08   C473782114           0.00            0.00   \n",
      "1   380   PAYMENT   32851.57  C1915112886           0.00            0.00   \n",
      "2   570  CASH_OUT 1131750.38  C1396198422     1131750.38            0.00   \n",
      "3   184  CASH_OUT   60519.74   C982551468       60519.74            0.00   \n",
      "4   162   CASH_IN   46716.01  C1759889425     7668050.60      7714766.61   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isPayment  \\\n",
      "0  C2096898696       649420.67       712347.75        0          0   \n",
      "1   M916879292            0.00            0.00        0          1   \n",
      "2  C1612235515       313070.53      1444820.92        1          0   \n",
      "3  C1378644910        54295.32       182654.50        1          0   \n",
      "4  C2059152908      2125468.75      2078752.75        0          0   \n",
      "\n",
      "   isMovement  accountDiff  \n",
      "0           1    649420.67  \n",
      "1           0         0.00  \n",
      "2           1    818679.85  \n",
      "3           1      6224.42  \n",
      "4           0   5542581.85  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   step            1000 non-null   int64  \n",
      " 1   type            1000 non-null   object \n",
      " 2   amount          1000 non-null   float64\n",
      " 3   nameOrig        1000 non-null   object \n",
      " 4   oldbalanceOrg   1000 non-null   float64\n",
      " 5   newbalanceOrig  1000 non-null   float64\n",
      " 6   nameDest        1000 non-null   object \n",
      " 7   oldbalanceDest  1000 non-null   float64\n",
      " 8   newbalanceDest  1000 non-null   float64\n",
      " 9   isFraud         1000 non-null   int64  \n",
      " 10  isPayment       1000 non-null   int64  \n",
      " 11  isMovement      1000 non-null   int64  \n",
      " 12  accountDiff     1000 non-null   float64\n",
      "dtypes: float64(6), int64(4), object(3)\n",
      "memory usage: 101.7+ KB\n",
      "None\n",
      "The number of fraudulent transactions is: 282\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "transactions = pd.read_csv('transactions_modified.csv')\n",
    "print(transactions.head())\n",
    "print(transactions.info()) #We dont have null values.\n",
    "\n",
    "#In this case the fraudulent transactions are in the \"isFraud\" column and the number that represents it is the number 1.\n",
    "#Thats why we can use the sum() method to know how many fraudulent transactions are in our dataset.\n",
    "# Sum method\n",
    "print(\"The number of fraudulent transactions is: {}\".format(transactions.isFraud.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Clean the Data\n",
    "\n",
    "2. We know that the amount of a given transaction is going to be important. Calculate summary statistics for this column. What does the distribution look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics on amount column\n",
      "count       1000.00\n",
      "mean      537307.96\n",
      "std      1423692.48\n",
      "min            0.00\n",
      "25%        29337.05\n",
      "50%       126530.51\n",
      "75%       301037.78\n",
      "max     10000000.00\n",
      "Name: amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Set pandas display option to avoid scientific notation\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"Summary statistics on amount column\")\n",
    "print(transactions.amount.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let’s create a new column called isPayment that assigns a 1 when type is “PAYMENT” or “DEBIT”, and a 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is neccesary bacause a pay made with a debit card is proceded at that time, so, we can count it as a payment, but\n",
    "#we already have the columns, so in this case we will duplicate it to complete the task and we will work with them.\n",
    "transactions['isPaymentPlusDebitCard'] = transactions['type'].apply(lambda x: 1 if x==\"PAYMENT\" or x==\"DEBIT\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Similarly, create a column called isMovement, which will capture if money moved out of the origin account. This column will have a value of 1 when type is either “CASH_OUT” or “TRANSFER”, and a 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['isMovementPlusTransfer'] = transactions['type'].apply(lambda x: 1 if x==\"CASH_OUT\" or x==\"TRANSFER\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. With financial fraud, another key factor to investigate would be the difference in value between the origin and destination account. Our theory, in this case, being that destination accounts with a significantly different value could be suspect of fraud. Let’s create a column called accountDiff with the absolute difference of the oldbalanceOrg and oldbalanceDest columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   step      type     amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0   206  CASH_OUT   62927.08   C473782114           0.00            0.00   \n",
      "1   380   PAYMENT   32851.57  C1915112886           0.00            0.00   \n",
      "2   570  CASH_OUT 1131750.38  C1396198422     1131750.38            0.00   \n",
      "3   184  CASH_OUT   60519.74   C982551468       60519.74            0.00   \n",
      "4   162   CASH_IN   46716.01  C1759889425     7668050.60      7714766.61   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isPayment  \\\n",
      "0  C2096898696       649420.67       712347.75        0          0   \n",
      "1   M916879292            0.00            0.00        0          1   \n",
      "2  C1612235515       313070.53      1444820.92        1          0   \n",
      "3  C1378644910        54295.32       182654.50        1          0   \n",
      "4  C2059152908      2125468.75      2078752.75        0          0   \n",
      "\n",
      "   isMovement  accountDiff  isPaymentPlusDebitCard  isMovementPlusTransfer  \\\n",
      "0           1    649420.67                       0                       1   \n",
      "1           0         0.00                       1                       0   \n",
      "2           1    818679.85                       0                       1   \n",
      "3           1      6224.42                       0                       1   \n",
      "4           0   5542581.85                       0                       0   \n",
      "\n",
      "   accountDiffN  \n",
      "0     649420.67  \n",
      "1          0.00  \n",
      "2     818679.85  \n",
      "3       6224.42  \n",
      "4    5542581.85  \n",
      "Differences: 0; 0; 0.0;\n"
     ]
    }
   ],
   "source": [
    "#We already have the column, but, to complete the task we will do a duplicate and we will work with it.\n",
    "transactions[\"accountDiffN\"] = abs(transactions.oldbalanceDest - transactions.oldbalanceOrg)\n",
    "\n",
    "print(transactions.head()) #We review the new columns added\n",
    "\n",
    "#Prove that the current columns in the dataset have the \"same data\":\n",
    "print(\"Differences: {}; {}; {};\".format(transactions['isPaymentPlusDebitCard'].sum() - transactions['isPayment'].sum(), transactions['isMovementPlusTransfer'].sum() - transactions['isMovement'].sum(),transactions[\"accountDiffN\"].sum()- transactions[\"accountDiff\"].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and Split the Data\n",
    "\n",
    "6. Before we can start training our model, we need to define our features and label columns. Our label column in this dataset is the isFraud field. Create a variable called features which will be an array consisting of the following fields: amount, isPayment, isMovement, accountDiff. Also create a variable called label with the column isFraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = transactions[[\"amount\", \"isPayment\", \"isMovement\", \"accountDiff\"]]\n",
    "label = transactions.isFraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Split the data into training and test sets using sklearn‘s train_test_split() method. We’ll use the training set to train the model and the test set to evaluate the model. Use a test_size value of 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the Data\n",
    "\n",
    "8. Since sklearn‘s Logistic Regression implementation uses Regularization, we need to scale our feature data. Create a StandardScaler object, .fit_transform() it on the training features, and .transform() the test features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Evaluate the Model\n",
    "\n",
    "9. Create a LogisticRegression model with sklearn and .fit() it on the training data. Fitting the model find the best coefficients for our selected features so it can more accurately predict our label. We will start with the default threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Run the model’s .score() method on the training data and print the training score. Scoring the model on the training data will process the training data through the trained model and will predict which transactions are fraudulent. The score returned is the percentage of correct classifications, or the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score (train data):\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Model score (train data):\")\n",
    "print(model.score(X_train, y_train)) #About 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Run the model’s .score() method on the test data and print the test score. Scoring the model on the test data will process the test data through the trained model and will predict which transactions are fraudulent. The score returned is the percentage of correct classifications, or the accuracy, and will be an indicator for the sucess of your model.\n",
    "\n",
    "How did your model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score (test data):\n",
      "0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Model score (test data):\")\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "#As with the training data, the model score is about 0.8, so it performs well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Print the coefficients for our model to see how important each feature column was for prediction. Which feature was most important? Least important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model coefficients: [[3.1348221  0.62141579 2.03149605 1.55698273]]\n"
     ]
    }
   ],
   "source": [
    "print(\"model coefficients: {}\".format(abs(model.coef_)))\n",
    "\n",
    "#In this case the most important feature was amount, because it has the largest coefficient.\n",
    "#In the least important feature was isPayment, because it has the shortest coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict With the Model\n",
    "\n",
    "13. Let’s use our model to process more transactions that have gone through our systems with the \"new transaction data\". Create a fourth array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New transaction data\n",
    "transaction1 = np.array([123456.78, 0.0, 1.0, 54670.1])\n",
    "transaction2 = np.array([98765.43, 1.0, 0.0, 8524.75])\n",
    "transaction3 = np.array([543678.31, 1.0, 0.0, 510025.5])\n",
    "\n",
    "transaction4 = np.array([78925.14, 0.0, 0.0, 25052.67])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Combine the new transactions and your_transaction into a single numpy array called sample_transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transactions = np.stack((transaction1, transaction2, transaction3, transaction4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Since our Logistic Regression model was trained on scaled feature data, we must also scale the feature data we are making predictions on. Using the StandardScaler object created earlier, apply its .transform() method to sample_transactions and save the result to sample_transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sample_transactions = scaler.transform(sample_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Which transactions are fraudulent? Use your model’s .predict() method on sample_transactions and print the result to find out. Also call your model’s .predict_proba() method on sample_transactions and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n",
      "[[0.60854125 0.39145875]\n",
      " [0.99787853 0.00212147]\n",
      " [0.99497029 0.00502971]\n",
      " [0.99100329 0.00899671]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(sample_transactions))\n",
    "\n",
    "print(model.predict_proba(sample_transactions)) #is the probability of a transaction not being fraudulent,\n",
    "                                                #and the 2nd column is the probability of a transaction being fraudulent\n",
    "\n",
    "#In this case all the transactions have a big possibility to not be fraudulent.\n",
    "#Except for the fourth array, in which the values were totally random."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
